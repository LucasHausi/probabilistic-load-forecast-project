{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b8196e2",
   "metadata": {},
   "source": [
    "# Bayesian LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeaf072c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import mlflow\n",
    "\n",
    "import blitz.modules as blitz_modules\n",
    "from blitz.utils import variational_estimator\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error\n",
    "\n",
    "import copy\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7610343",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "DATA_PATH = Path(\"../../data/processed\")\n",
    "\n",
    "EXPERIMENT_NAME = \"fs_06_load_calendar_future_weather\"\n",
    "OUTPUT_PATH = DATA_PATH / \"ml_data\" / EXPERIMENT_NAME\n",
    "OUTPUT_PATH.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df9e83c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cudnn.enabled       = True\n",
      "cudnn.benchmark     = False\n",
      "cudnn.deterministic = True\n"
     ]
    }
   ],
   "source": [
    "# Possible fix for stability in searches\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "print(\"cudnn.enabled       =\", torch.backends.cudnn.enabled)\n",
    "print(\"cudnn.benchmark     =\", torch.backends.cudnn.benchmark)\n",
    "print(\"cudnn.deterministic =\", torch.backends.cudnn.deterministic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148ffa52",
   "metadata": {},
   "source": [
    "## First: Start the MLFlow-Server for logging the experiments\n",
    "\n",
    "Run the following command: \n",
    "\n",
    "Powershell:\n",
    "\n",
    "mlflow server ` \n",
    "    --backend-store-uri sqlite:///mlflow.db ` \n",
    "    --default-artifact-root ./mlartifacts/  \n",
    "\n",
    "\n",
    "Bash / Git Bash / WSL / Linux / macOS\n",
    "mlflow server \\\n",
    "  --backend-store-uri sqlite:///mlflow.db \\\n",
    "  --default-artifact-root ./mlartifacts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9fcd4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"load_forecasting_bayesian_lstm\")\n",
    "\n",
    "mlflow.enable_system_metrics_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186b6e68",
   "metadata": {},
   "source": [
    "## Defining the model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5a2bd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "@variational_estimator\n",
    "class BayesianLSTM(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, horizon):\n",
    "        super().__init__()\n",
    "        self.lstm = blitz_modules.BayesianLSTM(\n",
    "            in_features=input_size,\n",
    "            out_features=hidden_size\n",
    "        )\n",
    "\n",
    "        self.fc = torch.nn.Linear(hidden_size, 2 * horizon) # times two, because we need to output a mean and variance for the GausianNLLLoss\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x is in format (batch_size, seq_len, input_size) but (seq_len, batch_size, input_size) is required\n",
    "        x = x.transpose(0, 1) # now in the correct format\n",
    "        out, _ = self.lstm(x) # (seq_len, batch_size, input_size)\n",
    "        h = out[-1, :, :] # The last hidden state (batch_size, hidden_size)\n",
    "        return self.fc(h) # (batch, 2 * horizon) each batch having the shape [mu_1, mu_2, ... var_1, var_2 ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45aa856",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e7edd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the scaler\n",
    "scalers_dir = OUTPUT_PATH / \"scalers\"\n",
    "\n",
    "with open(scalers_dir / \"y_scaler.pkl\", \"rb\") as f:\n",
    "    y_scaler = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea49404",
   "metadata": {},
   "source": [
    "# Define the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b53b204a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 164214 samples\n",
      "Val dataset:   39863 samples\n",
      "Test dataset:  39863 samples\n",
      "Sample shape: X=torch.Size([672, 19]), y=torch.Size([96])\n"
     ]
    }
   ],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset for time series forecasting.\"\"\"\n",
    "    \n",
    "    def __init__(self, X, y):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X: Input sequences (n_samples, window_size, n_features)\n",
    "            y: Target values (n_samples, forecast_horizon)\n",
    "        \"\"\"\n",
    "        self.X = torch.from_numpy(X).float()\n",
    "        self.y = torch.from_numpy(y).float()\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "X_train_seq = np.load(OUTPUT_PATH / \"X_train.npy\")\n",
    "y_train_seq = np.load(OUTPUT_PATH / \"y_train.npy\")\n",
    "train_dataset = TimeSeriesDataset(X_train_seq, y_train_seq)\n",
    "del X_train_seq, y_train_seq\n",
    "gc.collect()\n",
    "\n",
    "X_val_seq = np.load(OUTPUT_PATH / \"X_val.npy\")\n",
    "y_val_seq = np.load(OUTPUT_PATH / \"y_val.npy\")\n",
    "val_dataset = TimeSeriesDataset(X_val_seq, y_val_seq)\n",
    "del X_val_seq, y_val_seq\n",
    "gc.collect()\n",
    "\n",
    "X_test_seq = np.load(OUTPUT_PATH / \"X_test.npy\")\n",
    "y_test_seq = np.load(OUTPUT_PATH / \"y_test.npy\")\n",
    "test_dataset = TimeSeriesDataset(X_test_seq, y_test_seq)\n",
    "del X_test_seq, y_test_seq\n",
    "gc.collect()\n",
    "\n",
    "print(f\"Train dataset: {len(train_dataset)} samples\")\n",
    "print(f\"Val dataset:   {len(val_dataset)} samples\")\n",
    "print(f\"Test dataset:  {len(test_dataset)} samples\")\n",
    "print(f\"Sample shape: X={train_dataset[0][0].shape}, y={train_dataset[0][1].shape}\")\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b51067",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e4f75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    with mlflow.start_run(run_name=f\"trial_{trial.number}\", nested=True):\n",
    "        hidden_size = trial.suggest_int(\"hidden_size\", 64, 256, step=32)\n",
    "        lr = trial.suggest_float(\"lr\", 1e-4, 5e-3, log=True)\n",
    "        batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n",
    "        weight_decay = trial.suggest_float(\"weight_decay\", 1e-7, 1e-3, log=True)\n",
    "        sample_nbr = trial.suggest_categorical(\"sample_nbr\", [3, 5, 7, 10])\n",
    "        eval_sample_nbr = 50\n",
    "        kl_warmup_epochs = trial.suggest_int(\"kl_warmup_epochs\", 5, 20)\n",
    "\n",
    "        mlflow.log_params(trial.params)\n",
    "        mlflow.log_param(\"eval_sample_nbr\", eval_sample_nbr)\n",
    "\n",
    "        model = BayesianLSTM(\n",
    "            input_size=train_dataset[0][0].shape[-1],\n",
    "            hidden_size=hidden_size,\n",
    "            horizon=train_dataset[0][1].shape[-1],\n",
    "        ).to(DEVICE)\n",
    "\n",
    "        optimizer = torch.optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=lr,\n",
    "            weight_decay=weight_decay,\n",
    "        )\n",
    "\n",
    "        gauss_nll = torch.nn.GaussianNLLLoss(eps=1e-6, reduction=\"mean\") #torch.nn.MSELoss()\n",
    "\n",
    "        def nll_criterion(pred_params, y):\n",
    "            mu, log_var = torch.chunk(pred_params, 2, dim=-1)\n",
    "            var = torch.nn.functional.softplus(log_var) + 1e-6\n",
    "            return gauss_nll(mu, y, var)\n",
    "\n",
    "        train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "        val_dataloader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "        base_kl_weight = 1.0 / len(train_dataset)\n",
    "        best_val = float(\"inf\")\n",
    "        best_state = None\n",
    "        best_epoch = -1\n",
    "        patience = 10\n",
    "        wait = 0\n",
    "        num_epochs = 50\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            train_elbo = 0.0\n",
    "\n",
    "            kl_weight = base_kl_weight * min(1.0, (epoch + 1) / kl_warmup_epochs)\n",
    "\n",
    "            for xb, yb in train_dataloader:\n",
    "                xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                elbo = model.sample_elbo(\n",
    "                    inputs=xb,\n",
    "                    labels=yb,\n",
    "                    criterion=nll_criterion,\n",
    "                    sample_nbr=sample_nbr,\n",
    "                    complexity_cost_weight=kl_weight,\n",
    "                )\n",
    "\n",
    "                elbo.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "\n",
    "                train_elbo += elbo.item()\n",
    "\n",
    "            train_elbo /= len(train_dataloader)\n",
    "            mlflow.log_metric(\"train_elbo\", train_elbo, step=epoch)\n",
    "\n",
    "            model.eval()\n",
    "            val_elbo = 0.0\n",
    "            val_nll = 0.0\n",
    "            val_mu_preds = []\n",
    "            val_targets = []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for xb, yb in val_dataloader:\n",
    "                    xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "\n",
    "                    elbo = model.sample_elbo(\n",
    "                        inputs=xb,\n",
    "                        labels=yb,\n",
    "                        criterion=nll_criterion,\n",
    "                        sample_nbr=sample_nbr,\n",
    "                        complexity_cost_weight=kl_weight,\n",
    "                    )\n",
    "\n",
    "                    pred_samples = torch.stack([model(xb) for _ in range(eval_sample_nbr)], dim=0)\n",
    "                    mu_s, log_var_s = torch.chunk(pred_samples, 2, dim=-1)\n",
    "                    var_s = torch.nn.functional.softplus(log_var_s) + 1e-6\n",
    "                    mu_pred = mu_s.mean(dim=0)\n",
    "                    var_pred = var_s.mean(dim=0) + mu_s.var(dim=0, unbiased=False)\n",
    "                    nll = gauss_nll(mu_pred, yb, var_pred)\n",
    "\n",
    "                    val_mu_preds.append(mu_pred.detach().cpu().numpy())\n",
    "                    val_targets.append(yb.detach().cpu().numpy())\n",
    "\n",
    "                    val_elbo += elbo.item()\n",
    "                    val_nll += nll.item()\n",
    "\n",
    "            val_elbo /= len(val_dataloader)\n",
    "            val_nll /= len(val_dataloader)\n",
    "            y_pred_val = np.concatenate(val_mu_preds, axis=0)\n",
    "            y_true_val = np.concatenate(val_targets, axis=0)\n",
    "            val_mae = mean_absolute_error(y_true_val, y_pred_val)\n",
    "            val_rmse = root_mean_squared_error(y_true_val, y_pred_val)\n",
    "            val_mse = val_rmse ** 2\n",
    "            val_rmse_h = [\n",
    "                root_mean_squared_error(y_true_val[:, h], y_pred_val[:, h])\n",
    "                for h in [0, 3, 11, 23, 47, 95]\n",
    "            ]\n",
    "\n",
    "            mlflow.log_metric(\"val_elbo\", val_elbo, step=epoch)\n",
    "            mlflow.log_metric(\"val_nll\", val_nll, step=epoch)\n",
    "            mlflow.log_metric(\"val_mse\", val_mse, step=epoch)\n",
    "            mlflow.log_metric(\"val_mae\", val_mae, step=epoch)\n",
    "            mlflow.log_metric(\"val_rmse\", val_rmse, step=epoch)\n",
    "            for h_idx, rmse_h in enumerate(val_rmse_h):\n",
    "                mlflow.log_metric(f\"val_rmse_h{h_idx+1}\", rmse_h, step=epoch)\n",
    "            mlflow.log_metric(\"kl_weight\", kl_weight, step=epoch)\n",
    "\n",
    "            trial.report(val_nll, epoch)\n",
    "\n",
    "            if trial.should_prune():\n",
    "                del model, optimizer\n",
    "                gc.collect()\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                raise optuna.TrialPruned()\n",
    "\n",
    "            if val_nll < best_val:\n",
    "                best_val = val_nll\n",
    "                wait = 0\n",
    "                best_state = copy.deepcopy(model.state_dict())\n",
    "                best_epoch = epoch\n",
    "            else:\n",
    "                wait += 1\n",
    "\n",
    "            if wait >= patience:\n",
    "                break\n",
    "\n",
    "            print(\n",
    "                \n",
    "                f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "                f\"Train ELBO: {train_elbo:.4f}, \"\n",
    "                f\"Val ELBO: {val_elbo:.4f}, \"\n",
    "                f\"Val NLL: {val_nll:.6f}, \"\n",
    "                f\"Val MSE: {val_mse:.6f}, \"\n",
    "                f\"Val MAE: {val_mae:.6f}, \"\n",
    "                f\"KL w: {kl_weight:.2e}\"\n",
    "            )\n",
    "\n",
    "        if best_state is not None:\n",
    "            model.load_state_dict(best_state)\n",
    "            mlflow.log_metric(\"best_epoch\", best_epoch)\n",
    "            mlflow.pytorch.log_model(model, artifact_path=\"best_model\")\n",
    "\n",
    "        mlflow.log_metric(\"best_val_nll\", best_val)\n",
    "\n",
    "        del model, optimizer\n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        return best_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94c9a94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-09 14:28:53,697] A new study created in RDB with name: bayesian_lstm_nll_fs_06_load_calendar_future_weather\n",
      "2026/02/09 14:28:53 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2026/02/09 14:28:53 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5ab831ab88145d5a98b88091a60197a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/09 14:28:54 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2026/02/09 14:28:54 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n",
      "2026/02/09 14:51:05 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2026/02/09 14:51:05 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
      "2026/02/09 14:51:05 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2026/02/09 14:51:05 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run trial_0 at: http://127.0.0.1:5000/#/experiments/3/runs/80969d7697c04af2b7887bef94ddfd6f\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/3\n",
      "[W 2026-02-09 14:51:05,498] Trial 0 failed with parameters: {'hidden_size': 96, 'lr': 0.0011401031390814089, 'batch_size': 64, 'weight_decay': 1.2313185468743886e-06, 'sample_nbr': 7, 'kl_warmup_epochs': 10} because of the following error: IndexError('index 96 is out of bounds for axis 1 with size 96').\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lhaus\\Documents\\FH\\probabilistic-load-forecast-project\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\lhaus\\AppData\\Local\\Temp\\ipykernel_13900\\3717101500.py\", line 120, in objective\n",
      "    root_mean_squared_error(y_true_val[:, h], y_pred_val[:, h])\n",
      "                            ~~~~~~~~~~^^^^^^\n",
      "IndexError: index 96 is out of bounds for axis 1 with size 96\n",
      "[W 2026-02-09 14:51:05,500] Trial 0 failed with value None.\n",
      "üèÉ View run optuna_search_bayesian_lstm_nll_fs_06_load_calendar_future_weather at: http://127.0.0.1:5000/#/experiments/3/runs/22ea39d23a904097aa1c648539b198de\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/3\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 96 is out of bounds for axis 1 with size 96",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      4\u001b[39m study = optuna.create_study(\n\u001b[32m      5\u001b[39m     study_name=STUDY_NAME,\n\u001b[32m      6\u001b[39m     storage=STUDY_STORAGE,\n\u001b[32m   (...)\u001b[39m\u001b[32m     10\u001b[39m     pruner=optuna.pruners.MedianPruner(n_warmup_steps=\u001b[32m10\u001b[39m),\n\u001b[32m     11\u001b[39m )\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m mlflow.start_run(run_name=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33moptuna_search_bayesian_lstm_nll_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEXPERIMENT_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     mlflow.log_metric(\u001b[33m\"\u001b[39m\u001b[33mbest_val_nll\u001b[39m\u001b[33m\"\u001b[39m, study.best_value)\n\u001b[32m     16\u001b[39m     mlflow.log_params(study.best_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lhaus\\Documents\\FH\\probabilistic-load-forecast-project\\.venv\\Lib\\site-packages\\optuna\\study\\study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lhaus\\Documents\\FH\\probabilistic-load-forecast-project\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:67\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     80\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lhaus\\Documents\\FH\\probabilistic-load-forecast-project\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:164\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    161\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lhaus\\Documents\\FH\\probabilistic-load-forecast-project\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:262\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    255\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    258\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    259\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    261\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lhaus\\Documents\\FH\\probabilistic-load-forecast-project\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:205\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    207\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    208\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 120\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m    117\u001b[39m val_rmse = root_mean_squared_error(y_true_val, y_pred_val)\n\u001b[32m    118\u001b[39m val_mse = val_rmse ** \u001b[32m2\u001b[39m\n\u001b[32m    119\u001b[39m val_rmse_h = [\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m     root_mean_squared_error(\u001b[43my_true_val\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m]\u001b[49m, y_pred_val[:, h])\n\u001b[32m    121\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m [\u001b[32m1\u001b[39m, \u001b[32m4\u001b[39m, \u001b[32m12\u001b[39m, \u001b[32m24\u001b[39m, \u001b[32m48\u001b[39m, \u001b[32m96\u001b[39m]\n\u001b[32m    122\u001b[39m ]\n\u001b[32m    124\u001b[39m mlflow.log_metric(\u001b[33m\"\u001b[39m\u001b[33mval_elbo\u001b[39m\u001b[33m\"\u001b[39m, val_elbo, step=epoch)\n\u001b[32m    125\u001b[39m mlflow.log_metric(\u001b[33m\"\u001b[39m\u001b[33mval_nll\u001b[39m\u001b[33m\"\u001b[39m, val_nll, step=epoch)\n",
      "\u001b[31mIndexError\u001b[39m: index 96 is out of bounds for axis 1 with size 96"
     ]
    }
   ],
   "source": [
    "STUDY_NAME = f\"bayesian_lstm_nll_{EXPERIMENT_NAME}\"\n",
    "STUDY_STORAGE = \"sqlite:///optuna_bayesian_lstm.db\"\n",
    "\n",
    "study = optuna.create_study(\n",
    "    study_name=STUDY_NAME,\n",
    "    storage=STUDY_STORAGE,\n",
    "    load_if_exists=True,\n",
    "    direction=\"minimize\",\n",
    "    sampler=optuna.samplers.TPESampler(seed=1234),\n",
    "    pruner=optuna.pruners.MedianPruner(n_warmup_steps=10),\n",
    ")\n",
    "\n",
    "with mlflow.start_run(run_name=f\"optuna_search_bayesian_lstm_nll_{EXPERIMENT_NAME}\"):\n",
    "    study.optimize(objective, n_trials=50, show_progress_bar=True, gc_after_trial=True)\n",
    "    mlflow.log_metric(\"best_val_nll\", study.best_value)\n",
    "    mlflow.log_params(study.best_params)\n",
    "    mlflow.log_param(\"best_trial_number\", study.best_trial.number)\n",
    "\n",
    "best_params = study.best_params\n",
    "best_params\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd3802a",
   "metadata": {},
   "source": [
    "## Final training after the hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b2683e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/09 19:07:10 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2026/02/09 19:07:10 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70, Train ELBO: -0.0683, Val ELBO: -0.2934, Val NLL: -0.879707, KL w: 1.00e-05\n",
      "Epoch 2/70, Train ELBO: -0.0655, Val ELBO: -0.0866, Val NLL: -0.956000, KL w: 2.00e-05\n",
      "Epoch 3/70, Train ELBO: -0.0819, Val ELBO: -0.0886, Val NLL: -0.990061, KL w: 3.00e-05\n",
      "Epoch 4/70, Train ELBO: -0.2503, Val ELBO: -0.2983, Val NLL: -1.078628, KL w: 4.00e-05\n",
      "Epoch 5/70, Train ELBO: -0.4686, Val ELBO: -0.4372, Val NLL: -1.072030, KL w: 5.00e-05\n",
      "Epoch 6/70, Train ELBO: -0.6184, Val ELBO: -0.4761, Val NLL: -1.057159, KL w: 6.00e-05\n",
      "Epoch 7/70, Train ELBO: -0.6338, Val ELBO: -0.4570, Val NLL: -1.075121, KL w: 7.00e-05\n",
      "Epoch 8/70, Train ELBO: -0.5670, Val ELBO: -0.3971, Val NLL: -1.089457, KL w: 8.00e-05\n",
      "Epoch 9/70, Train ELBO: -0.4839, Val ELBO: -0.3220, Val NLL: -1.078291, KL w: 9.00e-05\n",
      "Epoch 10/70, Train ELBO: -0.4120, Val ELBO: -0.2388, Val NLL: -1.051803, KL w: 1.00e-04\n",
      "Epoch 11/70, Train ELBO: -0.4167, Val ELBO: -0.2394, Val NLL: -1.055545, KL w: 1.00e-04\n",
      "Epoch 12/70, Train ELBO: -0.4161, Val ELBO: -0.2496, Val NLL: -1.061343, KL w: 1.00e-04\n",
      "Epoch 13/70, Train ELBO: -0.4143, Val ELBO: -0.2093, Val NLL: -1.035303, KL w: 1.00e-04\n",
      "Epoch 14/70, Train ELBO: -0.4107, Val ELBO: -0.2377, Val NLL: -1.058229, KL w: 1.00e-04\n",
      "Epoch 15/70, Train ELBO: -0.4089, Val ELBO: -0.2439, Val NLL: -1.063134, KL w: 1.00e-04\n",
      "Epoch 16/70, Train ELBO: -0.4073, Val ELBO: -0.2285, Val NLL: -1.055329, KL w: 1.00e-04\n",
      "Epoch 17/70, Train ELBO: -0.4088, Val ELBO: -0.2620, Val NLL: -1.070338, KL w: 1.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/10 01:39:28 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2026/02/10 01:39:28 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
      "2026/02/10 01:39:28 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2026/02/10 01:39:28 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n",
      "2026/02/10 01:39:28 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run baysian_lstm_testrun_nll_fs_06_load_calendar_future_weather at: http://127.0.0.1:5000/#/experiments/3/runs/0df404bd6fee454788a60bacb548f643\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/10 01:39:28 WARNING mlflow.utils.requirements_utils: Found torch version (2.9.1+cu128) contains a local version label (+cu128). MLflow logged a pip requirement for this package as 'torch==2.9.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2026/02/10 01:39:43 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 70\n",
    "HIDDEN_SIZE = 64\n",
    "SAMPLE_NBR = 7\n",
    "VAL_EVAL_SAMPLE_NBR = 50\n",
    "TEST_SAMPLE_NBR = 90\n",
    "KL_WARMUP_EPOCHS = 10\n",
    "\n",
    "optim_kwargs = {\n",
    "    \"lr\": 3e-4,\n",
    "    \"weight_decay\": 1e-5,\n",
    "}\n",
    "\n",
    "model = BayesianLSTM(\n",
    "    input_size=train_dataset[0][0].shape[-1],\n",
    "    horizon=train_dataset[0][1].shape[-1],\n",
    "    hidden_size=HIDDEN_SIZE\n",
    ").to(DEVICE)\n",
    "\n",
    "optim = torch.optim.Adam(\n",
    "    params=model.parameters(),\n",
    "    **optim_kwargs\n",
    ")\n",
    "\n",
    "gauss_nll = torch.nn.GaussianNLLLoss(eps=1e-6, reduction=\"mean\") #torch.nn.MSELoss()\n",
    "\n",
    "def nll_criterion(pred_params, y):\n",
    "    mu, log_var = torch.chunk(pred_params, 2, dim=-1)\n",
    "    var = torch.nn.functional.softplus(log_var) + 1e-3\n",
    "    return gauss_nll(mu, y, var)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Scale KL term by dataset size; warm up to full weight over KL_WARMUP_EPOCHS.\n",
    "base_kl_weight = 1e-4 #1.0 / len(train_dataset)\n",
    "\n",
    "best_val = float(\"inf\")\n",
    "patience = 10\n",
    "wait = 0\n",
    "with mlflow.start_run(run_name=f\"baysian_lstm_testrun_nll_fs_06_load_calendar_future_weather\"):\n",
    "    mlflow.log_params(optim_kwargs)\n",
    "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "    mlflow.log_param(\"hidden_size\", HIDDEN_SIZE)\n",
    "    mlflow.log_param(\"sample_nbr\", SAMPLE_NBR)\n",
    "    mlflow.log_param(\"val_eval_sample_nbr\", VAL_EVAL_SAMPLE_NBR)\n",
    "    mlflow.log_param(\"kl_warmup_epochs\", KL_WARMUP_EPOCHS)\n",
    "    mlflow.log_param(\"base_kl_weight\", base_kl_weight)\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "        model.train()\n",
    "        train_elbo = 0.0\n",
    "\n",
    "        kl_weight = base_kl_weight * min(1.0, (epoch + 1) / KL_WARMUP_EPOCHS)\n",
    "\n",
    "        for xb, yb in train_dataloader:\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "\n",
    "            optim.zero_grad()\n",
    "\n",
    "            elbo = model.sample_elbo(\n",
    "                inputs=xb,\n",
    "                labels=yb,\n",
    "                criterion=nll_criterion,\n",
    "                sample_nbr=SAMPLE_NBR,\n",
    "                complexity_cost_weight=kl_weight\n",
    "            )\n",
    "\n",
    "            elbo.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optim.step()\n",
    "\n",
    "            train_elbo += elbo.item()\n",
    "\n",
    "        train_elbo /= len(train_dataloader)\n",
    "\n",
    "        mlflow.log_metric(\"train_elbo\", train_elbo, step=epoch)\n",
    "\n",
    "        model.eval()\n",
    "        val_elbo = 0.0\n",
    "        val_nll = 0.0\n",
    "\n",
    "        val_var_mean_acc = 0.0\n",
    "        val_var_min_acc = float(\"inf\")\n",
    "        val_var_max_acc = -float(\"inf\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_dataloader:\n",
    "                xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "\n",
    "                elbo = model.sample_elbo(\n",
    "                    inputs=xb,\n",
    "                    labels=yb,\n",
    "                    criterion=nll_criterion,\n",
    "                    sample_nbr=SAMPLE_NBR,\n",
    "                    complexity_cost_weight=kl_weight\n",
    "                )\n",
    "\n",
    "                pred_samples = torch.stack([model(xb) for _ in range(VAL_EVAL_SAMPLE_NBR)], dim=0)\n",
    "                mu_s, log_var_s = torch.chunk(pred_samples, 2, dim=-1)\n",
    "                var_s = torch.nn.functional.softplus(log_var_s) + 1e-6\n",
    "                mu_pred = mu_s.mean(dim=0)\n",
    "                var_pred = var_s.mean(dim=0) + mu_s.var(dim=0, unbiased=False)\n",
    "                nll = gauss_nll(mu_pred, yb, var_pred)\n",
    "\n",
    "                val_elbo += elbo.item()\n",
    "                val_nll += nll.item()\n",
    "\n",
    "                val_var_mean_acc += var_pred.mean().item()\n",
    "                val_var_min_acc = min(val_var_min_acc, var_pred.min().item())\n",
    "                val_var_max_acc = max(val_var_max_acc, var_pred.max().item())\n",
    "\n",
    "            val_elbo /= len(val_dataloader)\n",
    "            val_nll /= len(val_dataloader)\n",
    "            val_var_mean = val_var_mean_acc / len(val_dataloader)\n",
    "\n",
    "            mlflow.log_metric(\"val_elbo\", val_elbo, step=epoch)\n",
    "            mlflow.log_metric(\"val_nll\", val_nll, step=epoch)\n",
    "            mlflow.log_metric(\"kl_weight\", kl_weight, step=epoch)\n",
    "            \n",
    "            mlflow.log_metric(\"val_var_mean\", val_var_mean, step=epoch)\n",
    "            mlflow.log_metric(\"val_var_min\", val_var_min_acc, step=epoch)\n",
    "            mlflow.log_metric(\"val_var_max\", val_var_max_acc, step=epoch)\n",
    "\n",
    "            if val_nll < best_val:\n",
    "                best_val = val_nll\n",
    "                wait = 0\n",
    "                best_state = copy.deepcopy(model.state_dict())\n",
    "                best_epoch = epoch\n",
    "\n",
    "            else:\n",
    "                wait +=1\n",
    "            \n",
    "            if wait >= patience:\n",
    "                break\n",
    "\n",
    "            print(\n",
    "                f\"Epoch {epoch+1}/{NUM_EPOCHS}, \"\n",
    "                f\"Train ELBO: {train_elbo:.4f}, \"\n",
    "                f\"Val ELBO: {val_elbo:.4f}, \"\n",
    "                f\"Val NLL: {val_nll:.6f}, \"\n",
    "                f\"KL w: {kl_weight:.2e}\"\n",
    "            )\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "    mlflow.log_metric(\"best_epoch\", best_epoch)\n",
    "    mlflow.pytorch.log_model(model, artifact_path=\"best_model\")\n",
    "    best_model = model\n",
    "\n",
    "    best_model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_trues = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_dataloader:\n",
    "            xb = xb.to(DEVICE)\n",
    "            yb = yb.to(DEVICE)\n",
    "\n",
    "            samples = torch.stack([best_model(xb) for _ in range(TEST_SAMPLE_NBR)], dim=0)  # [S, N, 2H]\n",
    "            mu_s, log_var_s = torch.chunk(samples, 2, dim=-1)                                # [S, N, H], [S, N, H]\n",
    "            var_s = torch.nn.functional.softplus(log_var_s) + 1e-6\n",
    "\n",
    "            mu_scaled = mu_s.mean(dim=0)  # point forecast in scaled space, [N, H]\n",
    "            pred_var_scaled = var_s.mean(dim=0) + mu_s.var(dim=0, unbiased=False)  # total predictive var\n",
    "\n",
    "            N, H = mu_scaled.shape\n",
    "\n",
    "            y_pred = y_scaler.inverse_transform(mu_scaled.cpu().numpy().reshape(-1, 1)).reshape(N, H)\n",
    "            y_true = y_scaler.inverse_transform(yb.cpu().numpy().reshape(-1, 1)).reshape(N, H)\n",
    "\n",
    "            all_preds.append(y_pred)\n",
    "            all_trues.append(y_true)\n",
    "\n",
    "    # concat across batches\n",
    "    y_pred_full = np.concatenate(all_preds, axis=0)\n",
    "    y_true_full = np.concatenate(all_trues, axis=0)\n",
    "\n",
    "    mae = mean_absolute_error(y_true_full, y_pred_full)\n",
    "    rmse = root_mean_squared_error(y_true_full, y_pred_full)\n",
    "\n",
    "    mlflow.log_metric(\"test_mae_unscaled\", mae)\n",
    "    mlflow.log_metric(\"test_rmse_unscaled\", rmse)\n",
    "\n",
    "    for h in [0, 3, 11, 23, 47, 95]:\n",
    "        mlflow.log_metric(\n",
    "            f\"rmse_h{h+1}\",\n",
    "            root_mean_squared_error(y_true_full[:, h], y_pred_full[:, h])\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4e36b4",
   "metadata": {},
   "source": [
    "## Evaluation on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09cef8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoggedModel(artifact_location='mlflow-artifacts:/3/models/m-59d7d88d721247bc91c1ced7635a401f/artifacts', creation_timestamp=1770719453301, experiment_id='3', last_updated_timestamp=1770719462357, model_id='m-59d7d88d721247bc91c1ced7635a401f', model_type='', model_uri='models:/m-59d7d88d721247bc91c1ced7635a401f', name='best_model', source_run_id='0df404bd6fee454788a60bacb548f643', status=<LoggedModelStatus.READY: 'READY'>, status_message='')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranked_checkpoints = mlflow.search_logged_models(\n",
    "    filter_string=f\"source_run_id='0df404bd6fee454788a60bacb548f643'\",\n",
    "    order_by=[{\"field_name\": \"metrics.val_nll\", \"ascending\": True}],\n",
    "    output_format=\"list\",\n",
    ")\n",
    "\n",
    "best_checkpoint = ranked_checkpoints[0]\n",
    "best_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af8d76bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc67c94e4e934185b5bfd44ed1321c99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loaded_model = mlflow.pytorch.load_model(best_checkpoint.model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703b5b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/05 12:26:31 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2026/02/05 12:26:31 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    }
   ],
   "source": [
    "test_dataloader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True\n",
    ")\n",
    "loaded_model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_trues = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_dataloader:\n",
    "        xb = xb.to(DEVICE)\n",
    "        yb = yb.to(DEVICE)\n",
    "\n",
    "        samples = torch.stack([loaded_model(xb) for _ in range(TEST_SAMPLE_NBR)], dim=0)  # [S, N, 2H]\n",
    "        mu_s, log_var_s = torch.chunk(samples, 2, dim=-1)                                # [S, N, H], [S, N, H]\n",
    "        var_s = torch.nn.functional.softplus(log_var_s) + 1e-6\n",
    "\n",
    "        mu_scaled = mu_s.mean(dim=0)  # point forecast in scaled space, [N, H]\n",
    "        pred_var_scaled = var_s.mean(dim=0) + mu_s.var(dim=0, unbiased=False)  # total predictive var\n",
    "\n",
    "        N, H = mu_scaled.shape\n",
    "\n",
    "        y_pred = y_scaler.inverse_transform(mu_scaled.cpu().numpy().reshape(-1, 1)).reshape(N, H)\n",
    "        y_true = y_scaler.inverse_transform(yb.cpu().numpy().reshape(-1, 1)).reshape(N, H)\n",
    "\n",
    "        all_preds.append(y_pred)\n",
    "        all_trues.append(y_true)\n",
    "\n",
    "# concat across batches\n",
    "y_pred_full = np.concatenate(all_preds, axis=0)\n",
    "y_true_full = np.concatenate(all_trues, axis=0)\n",
    "\n",
    "mae = mean_absolute_error(y_true_full, y_pred_full)\n",
    "rmse = root_mean_squared_error(y_true_full, y_pred_full)\n",
    "\n",
    "mlflow.log_metric(\"test_mae_unscaled\", mae)\n",
    "mlflow.log_metric(\"test_rmse_unscaled\", rmse)\n",
    "\n",
    "for h in [0, 3, 11, 23, 47, 95]:\n",
    "    mlflow.log_metric(\n",
    "        f\"rmse_h{h+1}\",\n",
    "        root_mean_squared_error(y_true_full[:, h], y_pred_full[:, h])\n",
    "    )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
