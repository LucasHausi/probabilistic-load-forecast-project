{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a521e7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import optuna\n",
    "import mlflow\n",
    "import pickle\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from torch.utils.data import TensorDataset\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1805978d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "DATA_PATH = Path(\"../../data/processed\")\n",
    "\n",
    "EXPERIMENT_NAME = \"fs_06_load_calendar_future_weather\"\n",
    "OUTPUT_PATH = DATA_PATH / \"ml_data\" / EXPERIMENT_NAME\n",
    "OUTPUT_PATH.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b730c3",
   "metadata": {},
   "source": [
    "### Starting the mlflow server for model tracking\n",
    "\n",
    "To start the server run mlflow server --backend-store-uri sqlite:///mlflow.db --port 5000 in the terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14dd7df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/2', creation_time=1767875480688, experiment_id='2', last_update_time=1767875480688, lifecycle_stage='active', name='load_forecasting_vanilla_lstm_feature_eval', tags={'mlflow.experimentKind': 'custom_model_development'}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"load_forecasting_vanilla_lstm_feature_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd7f3601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cudnn.enabled       = True\n",
      "cudnn.benchmark     = False\n",
      "cudnn.deterministic = True\n"
     ]
    }
   ],
   "source": [
    "# Possible fix for stability in searches\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "print(\"cudnn.enabled       =\", torch.backends.cudnn.enabled)\n",
    "print(\"cudnn.benchmark     =\", torch.backends.cudnn.benchmark)\n",
    "print(\"cudnn.deterministic =\", torch.backends.cudnn.deterministic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c344909e",
   "metadata": {},
   "source": [
    "## Vanilla LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15abf1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaLSTM(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout, horizon):\n",
    "        super().__init__()\n",
    "        self.lstm = torch.nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.fc = torch.nn.Linear(hidden_size, horizon)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x) # (batch, seq_len, hidden_size)\n",
    "        h = out[:, -1, :] # The last hidden state from the last sequential LSTM Cell (batch, hidden_size)\n",
    "\n",
    "        return self.fc(h) # (batch, horizon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ec6236d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(DATA_PATH / \"data_combined.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db1e91f",
   "metadata": {},
   "source": [
    "## Feature Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79abafa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(X, y, window_size=4*24*7, forecast_horizon=4*24):\n",
    "    \"\"\"\n",
    "    Create sequences for time series forecasting.\n",
    "    \n",
    "    Args:\n",
    "        X: Feature array (n_samples, n_features)\n",
    "        y: Target array (n_samples,)\n",
    "        window_size: Number of time steps to look back\n",
    "        forecast_horizon: Number of time steps to forecast ahead\n",
    "        \n",
    "    Returns:\n",
    "        X_seq: Array of shape (n_sequences, window_size, n_features)\n",
    "        y_seq: Array of shape (n_sequences, forecast_horizon)\n",
    "    \"\"\"\n",
    "    n_samples = len(X)\n",
    "    \n",
    "    X_seq = []\n",
    "    y_seq = []\n",
    "    \n",
    "    for i in range(n_samples - window_size - forecast_horizon + 1):\n",
    "        X_seq.append(X[i:i+window_size])\n",
    "        y_seq.append(y[i+window_size:i+window_size+forecast_horizon])\n",
    "    \n",
    "    return (\n",
    "        np.array(X_seq, dtype=np.float32),\n",
    "        np.array(y_seq, dtype=np.float32),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa504896",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_SETS = {\n",
    "    \"fs_00_load_only\": [\n",
    "        \"actual_load_mw\"\n",
    "    ],\n",
    "\n",
    "    \"fs_01_load_calendar\": [\n",
    "        \"actual_load_mw\",\n",
    "        \"is_weekday\",\n",
    "        \"is_holiday\"\n",
    "    ],\n",
    "\n",
    "    \"fs_02_load_past_weather\": [\n",
    "        \"actual_load_mw\",\n",
    "        \"t2m\", \"ssrd\",\n",
    "        \"tp\", \"wind_speed\"\n",
    "    ],\n",
    "\n",
    "    \"fs_03_load_future_weather\": [\n",
    "        \"actual_load_mw\",\n",
    "        \"t2m_future\", \"ssrd_future\",\n",
    "        \"tp_future\", \"wind_speed_future\"\n",
    "    ],\n",
    "\n",
    "    \"fs_04_load_past_and_future_weather\": [\n",
    "        \"actual_load_mw\",\n",
    "        \"t2m\", \"ssrd\",\n",
    "        \"tp\", \"wind_speed\",\n",
    "        \"t2m_future\", \"ssrd_future\",\n",
    "        \"tp_future\", \"wind_speed_future\"\n",
    "    ],\n",
    "    \"fs_05_load_calendar_past_weather\": [\n",
    "        \"actual_load_mw\",\n",
    "        \"is_weekday\",\n",
    "        \"is_holiday\",\n",
    "        \"t2m\", \"ssrd\",\n",
    "        \"tp\", \"wind_speed\"\n",
    "    ],\n",
    "    \"fs_06_load_calendar_future_weather\": [\n",
    "        \"actual_load_mw\",\n",
    "        \"is_weekday\",\n",
    "        \"is_holiday\",\n",
    "        \"t2m_future\", \"ssrd_future\",\n",
    "        \"tp_future\", \"wind_speed_future\"\n",
    "    ],\n",
    "\n",
    "    \"fs_07_load_calendar_past_and_future_weather\": [\n",
    "        \"actual_load_mw\",\n",
    "        \"is_weekday\",\n",
    "        \"is_holiday\",\n",
    "        \"t2m\", \"ssrd\",\n",
    "        \"tp\", \"wind_speed\",\n",
    "        \"t2m_future\", \"ssrd_future\",\n",
    "        \"tp_future\", \"wind_speed_future\"\n",
    "    ],\n",
    "    \"fs_08_load_calendar_cyclic\": [\n",
    "        \"actual_load_mw\",\n",
    "        \"sin_tod\", \"cos_tod\",\n",
    "        \"sin_dow\", \"cos_dow\",\n",
    "        \"sin_doy\", \"cos_doy\",\n",
    "        \"is_dst\", \"is_dst_transition_day\",\n",
    "    ],\n",
    "    \"fs_10_load_calendar_cyclic_past_weather\": [\n",
    "        \"actual_load_mw\",\n",
    "        \"sin_tod\", \"cos_tod\",\n",
    "        \"sin_dow\", \"cos_dow\",\n",
    "        \"sin_doy\", \"cos_doy\",\n",
    "        \"is_dst\", \"is_dst_transition_day\",\n",
    "        \"t2m\", \"ssrd\",\n",
    "        \"tp\", \"wind_speed\",\n",
    "    ],\n",
    "    \"fs_11_load_calendar_cyclic_past_and_future_weather\": [\n",
    "        \"actual_load_mw\",\n",
    "        \"sin_tod\", \"cos_tod\",\n",
    "        \"sin_dow\", \"cos_dow\",\n",
    "        \"sin_doy\", \"cos_doy\",\n",
    "        \"is_dst\", \"is_dst_transition_day\",\n",
    "        \"t2m\", \"ssrd\",\n",
    "        \"tp\", \"wind_speed\",\n",
    "        \"t2m_future\", \"ssrd_future\",\n",
    "        \"tp_future\", \"wind_speed_future\",\n",
    "    ],\n",
    "    \"fs_12_load_calendar_cyclic_and_future_weather\": [\n",
    "        \"actual_load_mw\",\n",
    "        \"sin_tod\", \"cos_tod\",\n",
    "        \"sin_dow\", \"cos_dow\",\n",
    "        \"sin_doy\", \"cos_doy\",\n",
    "        \"is_dst\", \"is_dst_transition_day\",\n",
    "        \"t2m_future\", \"ssrd_future\",\n",
    "        \"tp_future\", \"wind_speed_future\",\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78575867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_feature_set(\n",
    "    df,\n",
    "    feature_cols,\n",
    "    window_size,\n",
    "    horizon,\n",
    "    tscv,\n",
    "    model_cls,\n",
    "    params,\n",
    "    device\n",
    "):\n",
    "    TARGET = \"actual_load_mw\"\n",
    "\n",
    "    X_all = df[feature_cols].values\n",
    "    y_all = df[TARGET].values\n",
    "\n",
    "    maes = []\n",
    "    rmses = []\n",
    "\n",
    "    rmse_h = {\n",
    "        1: [],\n",
    "        4: [],\n",
    "        12: [],\n",
    "        24: [],\n",
    "        48: [],\n",
    "        96: [],\n",
    "    }\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(tscv.split(X_all)):\n",
    "        with mlflow.start_run(run_name=f\"fold_{fold}\", nested=True):\n",
    "            X_train_raw, X_test_raw = X_all[train_idx], X_all[test_idx]\n",
    "            y_train_raw, y_test_raw = y_all[train_idx], y_all[test_idx]\n",
    "\n",
    "            # --- scaling (fit on train only)\n",
    "            X_scaler = RobustScaler()\n",
    "            y_scaler = RobustScaler()\n",
    "\n",
    "            X_train = X_scaler.fit_transform(X_train_raw)\n",
    "            y_train = y_scaler.fit_transform(y_train_raw.reshape(-1, 1)).ravel()\n",
    "\n",
    "            X_test = X_scaler.transform(X_test_raw)\n",
    "            y_test = y_scaler.transform(y_test_raw.reshape(-1, 1)).ravel()\n",
    "\n",
    "            # --- windowing\n",
    "            X_train_seq, y_train_seq = create_sequences(\n",
    "                X_train, y_train, window_size, horizon\n",
    "            )\n",
    "            X_test_seq, y_test_seq = create_sequences(\n",
    "                X_test, y_test, window_size, horizon\n",
    "            )\n",
    "\n",
    "            # --- datasets\n",
    "            train_ds = TensorDataset(\n",
    "                torch.from_numpy(X_train_seq),\n",
    "                torch.from_numpy(y_train_seq),\n",
    "            )\n",
    "            test_ds = TensorDataset(\n",
    "                torch.from_numpy(X_test_seq),\n",
    "                torch.from_numpy(y_test_seq),\n",
    "            )\n",
    "\n",
    "            train_loader = DataLoader(\n",
    "                train_ds,\n",
    "                batch_size=params[\"batch_size\"],\n",
    "                shuffle=True,\n",
    "            )\n",
    "            test_loader = DataLoader(\n",
    "                test_ds,\n",
    "                batch_size=params[\"batch_size\"],\n",
    "                shuffle=False,\n",
    "            )\n",
    "\n",
    "            # --- model\n",
    "            model = model_cls(\n",
    "                input_size=X_train_seq.shape[-1],\n",
    "                hidden_size=params[\"hidden_size\"],\n",
    "                num_layers=params[\"num_layers\"],\n",
    "                dropout=params[\"dropout\"],\n",
    "                horizon=horizon,\n",
    "            ).to(device)\n",
    "\n",
    "            optimizer = torch.optim.Adam(\n",
    "                model.parameters(),\n",
    "                lr=params[\"lr\"],\n",
    "                weight_decay=params[\"weight_decay\"],\n",
    "            )\n",
    "\n",
    "            criterion = torch.nn.MSELoss()\n",
    "\n",
    "            # --- training            \n",
    "            for epoch in range(30):\n",
    "                train_loss = 0.0\n",
    "                model.train()\n",
    "                for xb, yb in train_loader:\n",
    "                    xb, yb = xb.to(device), yb.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    loss = criterion(model(xb), yb)\n",
    "                    loss.backward()\n",
    "                    \n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "                    optimizer.step()\n",
    "\n",
    "                    train_loss += loss.item()\n",
    "\n",
    "                train_loss /= len(train_loader)\n",
    "                mlflow.log_metric(\"train_mse\", train_loss, step=epoch)\n",
    "\n",
    "                    \n",
    "\n",
    "            # --- evaluation (inverse-scaled)\n",
    "            model.eval()\n",
    "            preds, trues = [], []\n",
    "            test_loss = 0.0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for xb, yb in test_loader:\n",
    "                    xb, yb = xb.to(device), yb.to(device)\n",
    "                    y_pred_scaled = model(xb) # N, H\n",
    "                    test_loss += criterion(y_pred_scaled, yb).item()\n",
    "                    preds.append(y_pred_scaled.cpu().numpy())\n",
    "                    trues.append(yb.cpu().numpy())\n",
    "\n",
    "            test_loss /= len(test_loader)\n",
    "            mlflow.log_metric(\"test_mse\", test_loss)\n",
    "\n",
    "\n",
    "            preds = y_scaler.inverse_transform(np.vstack(preds))\n",
    "            trues = y_scaler.inverse_transform(np.vstack(trues))\n",
    "\n",
    "            mae = mean_absolute_error(preds, trues)\n",
    "            rmse = root_mean_squared_error(preds, trues)\n",
    "            \n",
    "            maes.append(mae)\n",
    "            rmses.append(rmse)\n",
    "\n",
    "            mlflow.log_metric(\"test_mae_unscaled\", mae)\n",
    "            mlflow.log_metric(\"test_rmse_unscaled\", rmse)\n",
    "\n",
    "            for h in [1, 4, 12, 24, 48, 96]:\n",
    "                rmse_h_val = root_mean_squared_error(\n",
    "                    trues[:, h-1],\n",
    "                    preds[:, h-1]\n",
    "                )\n",
    "                rmse_h[h].append(rmse_h_val)\n",
    "\n",
    "                mlflow.log_metric(f\"rmse_h{h}\", rmse_h_val)\n",
    "\n",
    "        del model, optimizer\n",
    "        torch.cuda.empty_cache()        \n",
    "\n",
    "    # --- aggregate CV metrics\n",
    "    mlflow.log_metric(\"cv_mae_mean\", np.mean(maes))\n",
    "    mlflow.log_metric(\"cv_mae_std\", np.std(maes))\n",
    "\n",
    "    mlflow.log_metric(\"cv_rmse_mean\", np.mean(rmses))\n",
    "    mlflow.log_metric(\"cv_rmse_std\", np.std(rmses))\n",
    "\n",
    "    for h in [1, 4, 12, 24, 48, 96]:\n",
    "        mlflow.log_metric(\n",
    "            f\"cv_rmse_h{h}_mean\",\n",
    "            np.mean(rmse_h[h])\n",
    "        )\n",
    "        mlflow.log_metric(\n",
    "            f\"cv_rmse_h{h}_std\",\n",
    "            np.std(rmse_h[h])\n",
    "        )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc9da7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run fold_0 at: http://127.0.0.1:5000/#/experiments/2/runs/eaa5cc4c821f4d87b031aca949dec9fe\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/2\n",
      "üèÉ View run fold_1 at: http://127.0.0.1:5000/#/experiments/2/runs/fc946bff565e4a0e90839d360baf93ba\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/2\n",
      "üèÉ View run fold_2 at: http://127.0.0.1:5000/#/experiments/2/runs/55716b66399f48a5bf51b5bba2b1e9c4\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/2\n",
      "üèÉ View run fold_3 at: http://127.0.0.1:5000/#/experiments/2/runs/fd055f49c9274c27b5e207d7683976e9\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/2\n",
      "üèÉ View run fold_4 at: http://127.0.0.1:5000/#/experiments/2/runs/bcade5e53de94bfe92618576fdbe2465\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/2\n",
      "üèÉ View run feature_eval_fs_04_load_past_and_future_weather at: http://127.0.0.1:5000/#/experiments/2/runs/73180af919424216b89d56db9c8e0e17\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/2\n",
      "üèÉ View run fold_0 at: http://127.0.0.1:5000/#/experiments/2/runs/bd5edfe195b84aa9b88c5c44ff1fd2be\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/2\n",
      "üèÉ View run fold_1 at: http://127.0.0.1:5000/#/experiments/2/runs/3bd4e352f4c04c9ba3a8d1dec972891a\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/2\n",
      "üèÉ View run fold_2 at: http://127.0.0.1:5000/#/experiments/2/runs/c531056e28224ad4928990bced9dafd8\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/2\n",
      "üèÉ View run fold_3 at: http://127.0.0.1:5000/#/experiments/2/runs/04bd5b99c118419ea53aaff5cea40e91\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/2\n",
      "üèÉ View run fold_4 at: http://127.0.0.1:5000/#/experiments/2/runs/2c479408006649efbcfbd2572205526d\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/2\n",
      "üèÉ View run feature_eval_fs_05_load_calendar_past_weather at: http://127.0.0.1:5000/#/experiments/2/runs/de3c828623664ba6835b55bf0463c46a\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/2\n",
      "üèÉ View run fold_0 at: http://127.0.0.1:5000/#/experiments/2/runs/8918b20162974d79b01c9c2290a71554\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/2\n",
      "üèÉ View run fold_1 at: http://127.0.0.1:5000/#/experiments/2/runs/56fba202b0404e5f9bf53447864c2a63\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/2\n",
      "üèÉ View run fold_2 at: http://127.0.0.1:5000/#/experiments/2/runs/a3b10e5c72b947b0848f4c8873fd4e18\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/2\n",
      "üèÉ View run fold_3 at: http://127.0.0.1:5000/#/experiments/2/runs/bdcce584065643509d8ac80fba6d9407\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/2\n",
      "üèÉ View run fold_4 at: http://127.0.0.1:5000/#/experiments/2/runs/d9a6a7381f6f4d4492d82b4187230102\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/2\n",
      "üèÉ View run feature_eval_fs_06_load_calendar_future_weather at: http://127.0.0.1:5000/#/experiments/2/runs/79cbeb33862943d2a9f07140519eaf98\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/2\n",
      "üèÉ View run fold_0 at: http://127.0.0.1:5000/#/experiments/2/runs/a28a70f2221745f18a28f06c3f23ddca\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/2\n",
      "üèÉ View run fold_1 at: http://127.0.0.1:5000/#/experiments/2/runs/4cb46624d531430aa313843947794c37\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/2\n",
      "üèÉ View run fold_2 at: http://127.0.0.1:5000/#/experiments/2/runs/a0156670763447309a407faf7d341740\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/2\n",
      "üèÉ View run fold_3 at: http://127.0.0.1:5000/#/experiments/2/runs/eddf8686d4a9428287001ebbe3f2d26d\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/2\n",
      "üèÉ View run fold_4 at: http://127.0.0.1:5000/#/experiments/2/runs/0764621c359b42fca49391636551c611\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/2\n",
      "üèÉ View run feature_eval_fs_07_load_calendar_past_and_future_weather at: http://127.0.0.1:5000/#/experiments/2/runs/f267ca19cf2a4b01afe5f3a5c816a4ca\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/2\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"hidden_size\": 224,\n",
    "    \"num_layers\": 2,\n",
    "    \"dropout\": 0.15,\n",
    "    \"lr\": 3e-4,\n",
    "    \"weight_decay\": 1e-5,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "\n",
    "\n",
    "N_SPLITS = 5\n",
    "tscv = TimeSeriesSplit(n_splits=N_SPLITS)\n",
    "\n",
    "for feature_set_name, features in FEATURE_SETS.items():\n",
    "    with mlflow.start_run(run_name=f\"feature_eval_{feature_set_name}\"):\n",
    "\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        run_feature_set(\n",
    "            df=df,\n",
    "            feature_cols=features,\n",
    "            window_size=4*24*7,\n",
    "            horizon=4*24,\n",
    "            tscv=tscv,\n",
    "            model_cls=VanillaLSTM,\n",
    "            params=params,\n",
    "            device=DEVICE\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472c8c81",
   "metadata": {},
   "source": [
    "## Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8b2e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load numpy arrays\n",
    "scalers_dir = OUTPUT_PATH / \"scalers\"\n",
    "\n",
    "\n",
    "X_train_seq = np.load(OUTPUT_PATH / \"X_train.npy\")\n",
    "y_train_seq = np.load(OUTPUT_PATH / \"y_train.npy\")\n",
    "X_val_seq = np.load(OUTPUT_PATH / \"X_val.npy\")\n",
    "y_val_seq = np.load(OUTPUT_PATH / \"y_val.npy\")\n",
    "X_test_seq = np.load(OUTPUT_PATH / \"X_test.npy\")\n",
    "y_test_seq = np.load(OUTPUT_PATH / \"y_test.npy\")\n",
    "\n",
    "\n",
    "with open(scalers_dir / \"y_scaler.pkl\", \"rb\") as f:\n",
    "    y_scaler = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee66938",
   "metadata": {},
   "source": [
    "### PyTorch Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50712582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 164278 samples\n",
      "Val dataset:   39879 samples\n",
      "Test dataset:  39879 samples\n",
      "Sample shape: X=torch.Size([672, 5]), y=torch.Size([96])\n"
     ]
    }
   ],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset for time series forecasting.\"\"\"\n",
    "    \n",
    "    def __init__(self, X, y):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X: Input sequences (n_samples, window_size, n_features)\n",
    "            y: Target values (n_samples, forecast_horizon)\n",
    "        \"\"\"\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.y = torch.FloatTensor(y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_dataset = TimeSeriesDataset(X_train_seq, y_train_seq)\n",
    "val_dataset = TimeSeriesDataset(X_val_seq, y_val_seq)\n",
    "test_dataset = TimeSeriesDataset(X_test_seq, y_test_seq)\n",
    "\n",
    "print(f\"Train dataset: {len(train_dataset)} samples\")\n",
    "print(f\"Val dataset:   {len(val_dataset)} samples\")\n",
    "print(f\"Test dataset:  {len(test_dataset)} samples\")\n",
    "print(f\"Sample shape: X={train_dataset[0][0].shape}, y={train_dataset[0][1].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f07ed88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def objective(trial):\n",
    "    with mlflow.start_run(run_name=f\"trial_{trial.number}\", nested=True):\n",
    "\n",
    "        trial_dir = OUTPUT_PATH / \"artifacts\" / f\"trial_{trial.number}\"\n",
    "        trial_dir.mkdir(parents=True, exist_ok=True)\n",
    "        best_model_path = trial / \"best_model.pt\"\n",
    "\n",
    "        hidden_size = trial.suggest_int(\"hidden_size\", 64, 256, step=32)\n",
    "        num_layers  = trial.suggest_int(\"num_layers\", 1, 3)\n",
    "        dropout = 0.0 if num_layers == 1 else trial.suggest_float(\"dropout\", 0.0, 0.4)\n",
    "        lr          = trial.suggest_float(\"lr\", 1e-4, 5e-3, log=True)\n",
    "        batch_size  = trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n",
    "        weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-2, log=True)\n",
    "\n",
    "\n",
    "        mlflow.log_params(trial.params)\n",
    "\n",
    "\n",
    "        model = VanillaLSTM(\n",
    "            input_size=X_train_seq.shape[-1],\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout,\n",
    "            horizon=y_train_seq.shape[-1]\n",
    "        ).to(DEVICE)\n",
    "\n",
    "        optimizer = torch.optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=lr,\n",
    "            weight_decay=weight_decay\n",
    "        )\n",
    "\n",
    "        criterion = torch.nn.MSELoss()\n",
    "\n",
    "        train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "        val_dataloader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False\n",
    "        )\n",
    "        \n",
    "        best_val = float(\"inf\")\n",
    "        patience = 10\n",
    "        wait = 0\n",
    "\n",
    "        for epoch in range(50):\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            for xb, yb in train_dataloader:\n",
    "                xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "                optimizer.zero_grad()\n",
    "                preds = model(xb)\n",
    "                torch.cuda.synchronize()\n",
    "\n",
    "                loss = criterion(preds, yb)\n",
    "                loss.backward()\n",
    "                torch.cuda.synchronize()\n",
    "\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                torch.cuda.synchronize()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                \n",
    "\n",
    "            train_loss /= len(train_dataloader)\n",
    "            mlflow.log_metric(\"train_mse\", train_loss, step=epoch)\n",
    "\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for xb, yb in val_dataloader:\n",
    "                    xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "                    preds = model(xb)\n",
    "                    val_loss += criterion(preds, yb).item()\n",
    "\n",
    "            val_loss /= len(val_dataloader)\n",
    "\n",
    "            mlflow.log_metric(\"val_mse\", val_loss, step=epoch)\n",
    "\n",
    "            trial.report(val_loss, epoch)\n",
    "\n",
    "            if trial.should_prune():\n",
    "                raise optuna.TrialPruned()\n",
    "\n",
    "            if val_loss < best_val:\n",
    "                best_val = val_loss\n",
    "                wait = 0\n",
    "\n",
    "                torch.save(\n",
    "                {\n",
    "                    \"model_state_dict\": model.state_dict(),\n",
    "                    \"epoch\": epoch,\n",
    "                    \"val_mse\": val_loss,\n",
    "                    \"trial_number\": trial.number,\n",
    "                    \"params\": trial.params,\n",
    "                },\n",
    "                    best_model_path\n",
    "                )\n",
    "                mlflow.log_artifact(str(best_model_path), artifact_path=\"models\")\n",
    "            else:\n",
    "                wait += 1\n",
    "\n",
    "            if wait >= patience:\n",
    "                break\n",
    "\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "        return best_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b366a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    sampler=optuna.samplers.TPESampler(seed=1234),\n",
    "    pruner=optuna.pruners.MedianPruner(n_warmup_steps=10)\n",
    ")\n",
    "with mlflow.start_run(run_name=\"optuna_search\"):\n",
    "    study.optimize(objective, n_trials=50, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e454b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_size': 224,\n",
       " 'num_layers': 3,\n",
       " 'dropout': 0.023414518146625124,\n",
       " 'lr': 0.0011000556535137422,\n",
       " 'batch_size': 128,\n",
       " 'weight_decay': 3.54214337413836e-05}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9f3107",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'hidden_size': 224,\n",
    "    'num_layers': 3,\n",
    "    'dropout': 0.023414518146625124,\n",
    "    'lr': 0.0011000556535137422,\n",
    "    'batch_size': 128,\n",
    "    'weight_decay': 3.54214337413836e-05\n",
    "}\n",
    "\n",
    "\n",
    "model_kwargs = {k: best_params[k] for k in (\"hidden_size\", \"num_layers\", \"dropout\")}\n",
    "optim_kwargs = {k: best_params[k] for k in (\"lr\", \"weight_decay\")}\n",
    "batch_size = best_params[\"batch_size\"]\n",
    "\n",
    "model = VanillaLSTM(\n",
    "    input_size=X_train_seq.shape[-1],\n",
    "    horizon=y_train_seq.shape[-1],\n",
    "    **model_kwargs\n",
    ").to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    **optim_kwargs\n",
    ")\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "best_val = float(\"inf\")\n",
    "patience = 10\n",
    "wait = 0\n",
    "\n",
    "with mlflow.start_run(run_name=f\"final_model_training_weather_load\"):\n",
    "    for epoch in range(50):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for xb, yb in train_dataloader:\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(xb)\n",
    "\n",
    "            loss = criterion(preds, yb)\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_dataloader)\n",
    "        mlflow.log_metric(\"train_mse\", train_loss, step=epoch)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_dataloader:\n",
    "                xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "                preds = model(xb)\n",
    "                val_loss += criterion(preds, yb).item()\n",
    "\n",
    "        val_loss /= len(val_dataloader)\n",
    "        mlflow.log_metric(\"val_mse\", val_loss, step=epoch)\n",
    "\n",
    "        mlflow.log_params(model_kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f9d7b2",
   "metadata": {},
   "source": [
    "After the hyperparameter search is finished the cudnn settings can be reversed for a faster final training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300dd8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cudnn.enabled       = True\n",
      "cudnn.benchmark     = True\n",
      "cudnn.deterministic = False\n"
     ]
    }
   ],
   "source": [
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "print(\"cudnn.enabled       =\", torch.backends.cudnn.enabled)\n",
    "print(\"cudnn.benchmark     =\", torch.backends.cudnn.benchmark)\n",
    "print(\"cudnn.deterministic =\", torch.backends.cudnn.deterministic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b875a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_trues = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_dataloader:\n",
    "        xb = xb.to(DEVICE)\n",
    "        yb = yb.to(DEVICE)\n",
    "\n",
    "        y_pred_scaled = model(xb)\n",
    "\n",
    "        N, H = y_pred_scaled.shape\n",
    "\n",
    "        y_pred = y_scaler.inverse_transform(\n",
    "            y_pred_scaled.cpu().numpy().reshape(-1, 1)\n",
    "        ).reshape(N, H)\n",
    "\n",
    "        y_true = y_scaler.inverse_transform(\n",
    "            yb.cpu().numpy().reshape(-1, 1)\n",
    "        ).reshape(N, H)\n",
    "\n",
    "        all_preds.append(y_pred)\n",
    "        all_trues.append(y_true)\n",
    "\n",
    "# concat across batches\n",
    "y_pred_full = np.concatenate(all_preds, axis=0)\n",
    "y_true_full = np.concatenate(all_trues, axis=0)\n",
    "\n",
    "mae = mean_absolute_error(y_true_full, y_pred_full)\n",
    "rmse = root_mean_squared_error(y_true_full, y_pred_full)\n",
    "\n",
    "mlflow.log_metric(\"test_mae_unscaled\", mae)\n",
    "mlflow.log_metric(\"test_rmse_unscaled\", rmse)\n",
    "\n",
    "for h in [0, 3, 11, 23, 47, 95]:\n",
    "    mlflow.log_metric(\n",
    "        f\"rmse_h{h+1}\",\n",
    "        root_mean_squared_error(y_true_full[:, h], y_pred_full[:, h])\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966a20b3",
   "metadata": {},
   "source": [
    "With this final model, the unscaled metrics can be observed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42016cd",
   "metadata": {},
   "source": [
    "## Final Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2cecf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"hidden_size\": 224,\n",
    "    \"num_layers\": 2,\n",
    "    \"dropout\": 0.15,\n",
    "    \"lr\": 3e-4,\n",
    "    \"weight_decay\": 1e-5,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "\n",
    "model_kwargs = {k: params[k] for k in (\"hidden_size\", \"num_layers\", \"dropout\")}\n",
    "optim_kwargs = {k: params[k] for k in (\"lr\", \"weight_decay\")}\n",
    "batch_size = params[\"batch_size\"]\n",
    "\n",
    "N_SPLITS = 5\n",
    "tscv = TimeSeriesSplit(n_splits=N_SPLITS)\n",
    "model = VanillaLSTM(\n",
    "    input_size=X_train_seq.shape[-1],\n",
    "    horizon=y_train_seq.shape[-1],\n",
    "    **model_kwargs\n",
    ").to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    **optim_kwargs\n",
    ")\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "best_val = float(\"inf\")\n",
    "patience = 10\n",
    "wait = 0\n",
    "\n",
    "with mlflow.start_run(run_name=f\"feature_evaluation_v2_with_weather_data\"):\n",
    "    \n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    for epoch in range(50):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for xb, yb in train_dataloader:\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(xb)\n",
    "\n",
    "            loss = criterion(preds, yb)\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_dataloader)\n",
    "        mlflow.log_metric(\"train_mse\", train_loss, step=epoch)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_dataloader:\n",
    "                xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "                preds = model(xb)\n",
    "                val_loss += criterion(preds, yb).item()\n",
    "\n",
    "        val_loss /= len(val_dataloader)\n",
    "        mlflow.log_metric(\"val_mse\", val_loss, step=epoch)\n",
    "\n",
    "\n",
    "        if val_loss < best_val:\n",
    "            best_val = val_loss\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "\n",
    "        if wait >= patience:\n",
    "                break\n",
    "    \n",
    "\n",
    "    test_dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_trues = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_dataloader:\n",
    "            xb = xb.to(DEVICE)\n",
    "            yb = yb.to(DEVICE)\n",
    "\n",
    "            y_pred_scaled = model(xb)\n",
    "\n",
    "            N, H = y_pred_scaled.shape\n",
    "\n",
    "            y_pred = y_scaler.inverse_transform(\n",
    "                y_pred_scaled.cpu().numpy().reshape(-1, 1)\n",
    "            ).reshape(N, H)\n",
    "\n",
    "            y_true = y_scaler.inverse_transform(\n",
    "                yb.cpu().numpy().reshape(-1, 1)\n",
    "            ).reshape(N, H)\n",
    "\n",
    "            all_preds.append(y_pred)\n",
    "            all_trues.append(y_true)\n",
    "\n",
    "    # concat across batches\n",
    "    y_pred_full = np.concatenate(all_preds, axis=0)\n",
    "    y_true_full = np.concatenate(all_trues, axis=0)\n",
    "\n",
    "    mae = mean_absolute_error(y_true_full, y_pred_full)\n",
    "    rmse = root_mean_squared_error(y_true_full, y_pred_full)\n",
    "\n",
    "    mlflow.log_metric(\"test_mae_unscaled\", mae)\n",
    "    mlflow.log_metric(\"test_rmse_unscaled\", rmse)\n",
    "\n",
    "    for h in [0, 3, 11, 23, 47, 95]:\n",
    "        mlflow.log_metric(\n",
    "            f\"rmse_h{h+1}\",\n",
    "            root_mean_squared_error(y_true_full[:, h], y_pred_full[:, h])\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf92cdd0",
   "metadata": {},
   "source": [
    "### Saving the model and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bb37d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = OUTPUT_PATH / \"models\"\n",
    "model_config_path = model_dir / \"model_config.json\"\n",
    "\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "torch.save(model.state_dict(), model_dir/ \"final_model_v1_state.pt\")\n",
    "\n",
    "with open(model_config_path, \"w\") as f:\n",
    "    json.dump(params, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e9e6ee",
   "metadata": {},
   "source": [
    "Perhaps save the full model also to experiment what version is better for the upcoming experiments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93791f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, OUTPUT_PATH / \"models/final_model_v1_full.pt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
