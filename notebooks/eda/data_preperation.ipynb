{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3554197b",
   "metadata": {},
   "source": [
    "# Data Preperation for modelling in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5244c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e7f88bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = \"fs_06_load_calendar_future_weather\"\n",
    "DATA_DIR = Path(\"../../data/processed\")\n",
    "OUTPUT_DIR= DATA_DIR / \"ml_data\" / EXPERIMENT_NAME\n",
    "\n",
    "SCALERS_DIR = OUTPUT_DIR / \"scalers\"\n",
    "\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "SCALERS_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb279f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_parquet(DATA_DIR / \"data_combined.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03feff9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"actual_load_mw\"].to_frame()\n",
    "X = df\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aebe0b7",
   "metadata": {},
   "source": [
    "## Intermediate Outlier check\n",
    "Checking for outliers is important to help choose the most appropriate scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a985842d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "610e59f7-8dd0-456a-bc8d-ac9ec6795764",
       "rows": [
        [
         "tp_future",
         "0.10405248751236625"
        ],
        [
         "tp",
         "0.10390682374076704"
        ],
        [
         "ssrd_future",
         "0.051929134575116984"
        ],
        [
         "ssrd",
         "0.051904857279850454"
        ],
        [
         "wind_speed_future",
         "0.02481139576239811"
        ],
        [
         "wind_speed",
         "0.024714286581331974"
        ],
        [
         "actual_load_mw",
         "0.0"
        ],
        [
         "t2m",
         "0.0"
        ],
        [
         "t2m_future",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 9
       }
      },
      "text/plain": [
       "tp_future            0.104052\n",
       "tp                   0.103907\n",
       "ssrd_future          0.051929\n",
       "ssrd                 0.051905\n",
       "wind_speed_future    0.024811\n",
       "wind_speed           0.024714\n",
       "actual_load_mw       0.000000\n",
       "t2m                  0.000000\n",
       "t2m_future           0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def iqr_outlier_stats(X):\n",
    "    stats = {}\n",
    "    for col in X.columns:\n",
    "        q1 = X[col].quantile(0.25)\n",
    "        q3 = X[col].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        if iqr == 0:\n",
    "            stats[col] = 0.0\n",
    "            continue\n",
    "        mask = (X[col] < q1 - 1.5 * iqr) | (X[col] > q3 + 1.5 * iqr)\n",
    "        stats[col] = mask.mean()\n",
    "    return pd.Series(stats).sort_values(ascending=False)\n",
    "\n",
    "outlier_frac = iqr_outlier_stats(X_train.select_dtypes(include=np.number))\n",
    "outlier_frac\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6fb2db89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "actual_load_mw    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_frac = iqr_outlier_stats(y_train)\n",
    "outlier_frac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbeb86a",
   "metadata": {},
   "source": [
    "Seems like the total precipitation has a 10% outlier rate. This would suggest using a robust scaler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f015492",
   "metadata": {},
   "source": [
    "## Scale Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c508ecde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled shapes - Train: (164763, 11), Val: (40576, 11), Test: (40577, 11)\n"
     ]
    }
   ],
   "source": [
    "X_scaler = RobustScaler()\n",
    "y_scaler = RobustScaler()\n",
    "\n",
    "# Fit scalers on training data only\n",
    "X_train_scaled = X_scaler.fit_transform(X_train)\n",
    "y_train_scaled = y_scaler.fit_transform(y_train).squeeze()\n",
    "\n",
    "# Transform validation and test sets using fitted scalers\n",
    "X_val_scaled = X_scaler.transform(X_val)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "y_val_scaled = y_scaler.transform(y_val).squeeze()\n",
    "y_test_scaled = y_scaler.transform(y_test).squeeze()\n",
    "\n",
    "print(f\"Scaled shapes - Train: {X_train_scaled.shape}, Val: {X_val_scaled.shape}, Test: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbe938b",
   "metadata": {},
   "source": [
    "## Windowing\n",
    "\n",
    "Create sequences for time series forecasting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2b752b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sequences: (164278, 672, 5) -> (164278, 96)\n",
      "Val sequences:   (39879, 672, 5) -> (39879, 96)\n",
      "Test sequences:  (39879, 672, 5) -> (39879, 96)\n"
     ]
    }
   ],
   "source": [
    "def create_sequences(X, y, window_size=4*24*7, forecast_horizon=4*24):\n",
    "    \"\"\"\n",
    "    Create sequences for time series forecasting.\n",
    "    \n",
    "    Args:\n",
    "        X: Feature array (n_samples, n_features)\n",
    "        y: Target array (n_samples,)\n",
    "        window_size: Number of time steps to look back\n",
    "        forecast_horizon: Number of time steps to forecast ahead\n",
    "        \n",
    "    Returns:\n",
    "        X_seq: Array of shape (n_sequences, window_size, n_features)\n",
    "        y_seq: Array of shape (n_sequences, forecast_horizon)\n",
    "    \"\"\"\n",
    "    n_samples = len(X)\n",
    "    \n",
    "    X_seq = []\n",
    "    y_seq = []\n",
    "    \n",
    "    for i in range(n_samples - window_size - forecast_horizon + 1):\n",
    "        X_seq.append(X[i:i+window_size])\n",
    "        y_seq.append(y[i+window_size:i+window_size+forecast_horizon])\n",
    "    \n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "# Configuration\n",
    "WINDOW_SIZE = 4*24*7  # Look back the last 7 days\n",
    "FORECAST_HORIZON = 4*24  # Forecast 96 steps ahead\n",
    "\n",
    "# Create sequences for each split\n",
    "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train_scaled, WINDOW_SIZE, FORECAST_HORIZON)\n",
    "X_val_seq, y_val_seq = create_sequences(X_val_scaled, y_val_scaled, WINDOW_SIZE, FORECAST_HORIZON)\n",
    "X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test_scaled, WINDOW_SIZE, FORECAST_HORIZON)\n",
    "\n",
    "print(f\"Train sequences: {X_train_seq.shape} -> {y_train_seq.shape}\")\n",
    "print(f\"Val sequences:   {X_val_seq.shape} -> {y_val_seq.shape}\")\n",
    "print(f\"Test sequences:  {X_test_seq.shape} -> {y_test_seq.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ad6de4",
   "metadata": {},
   "source": [
    "## Save Data and Artifacts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a499fbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data to ..\\..\\data\\processed\\ml_data\\fs_002_weather_and_load\n"
     ]
    }
   ],
   "source": [
    "# Save numpy arrays\n",
    "np.save(OUTPUT_DIR / \"X_train.npy\", X_train_seq)\n",
    "np.save(OUTPUT_DIR / \"y_train.npy\", y_train_seq)\n",
    "np.save(OUTPUT_DIR / \"X_val.npy\", X_val_seq)\n",
    "np.save(OUTPUT_DIR / \"y_val.npy\", y_val_seq)\n",
    "np.save(OUTPUT_DIR / \"X_test.npy\", X_test_seq)\n",
    "np.save(OUTPUT_DIR / \"y_test.npy\", y_test_seq)\n",
    "\n",
    "# Save scalers\n",
    "with open(SCALERS_DIR / \"X_scaler.pkl\", \"wb\") as f:\n",
    "    pickle.dump(X_scaler, f)\n",
    "with open(SCALERS_DIR / \"y_scaler.pkl\", \"wb\") as f:\n",
    "    pickle.dump(y_scaler, f)\n",
    "\n",
    "# Save metadata\n",
    "meta = {\n",
    "    \"window_size\": WINDOW_SIZE,\n",
    "    \"forecast_horizon\": FORECAST_HORIZON,\n",
    "    \"n_features\": X_train_scaled.shape[1],\n",
    "    \"feature_names\": list(X.columns),\n",
    "    \"train_samples\": len(X_train_seq),\n",
    "    \"val_samples\": len(X_val_seq),\n",
    "    \"test_samples\": len(X_test_seq),\n",
    "    \"train_date_range\": {\n",
    "        \"start\": str(X_train.index.min()),\n",
    "        \"end\": str(X_train.index.max())\n",
    "    },\n",
    "    \"val_date_range\": {\n",
    "        \"start\": str(X_val.index.min()),\n",
    "        \"end\": str(X_val.index.max())\n",
    "    },\n",
    "    \"test_date_range\": {\n",
    "        \"start\": str(X_test.index.min()),\n",
    "        \"end\": str(X_test.index.max())\n",
    "    },\n",
    "    \"scaler_type\": \"RobustScaler\",\n",
    "    \"split_ratio\": {\n",
    "        \"train\": 0.7,\n",
    "        \"val\": 0.15,\n",
    "        \"test\": 0.15\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(OUTPUT_DIR / \"meta.json\", \"w\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "print(f\"Saved data to {OUTPUT_DIR}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "probabilistic-load-forecast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
