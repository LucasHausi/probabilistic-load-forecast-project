{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "209038ce",
   "metadata": {},
   "source": [
    "# Model Comparisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9e111e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9c8dd6",
   "metadata": {},
   "source": [
    "## First: Start the MLFlow-Server for logging the experiments\n",
    "\n",
    "Run the following command: \n",
    "\n",
    "Powershell:\n",
    "\n",
    "mlflow server ` \n",
    "    --backend-store-uri sqlite:///mlflow.db ` \n",
    "    --default-artifact-root ./mlartifacts/  \n",
    "\n",
    "\n",
    "Bash / Git Bash / WSL / Linux / macOS\n",
    "mlflow server \\\n",
    "  --backend-store-uri sqlite:///mlflow.db \\\n",
    "  --default-artifact-root ./mlartifacts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6401261",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0c015c",
   "metadata": {},
   "source": [
    "## Load the best models (LSTM, Bayesian LSTM, Propeht) and Perfomance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7008b355",
   "metadata": {},
   "outputs": [],
   "source": [
    "perfomance_df = pd.DataFrame(columns=[\"Model\", \"RSME_Overall\", \"MAE_Overall\", \"RSME_h1\", \"RSME_h4\", \"RSME_h12\", \"RSME_h24\", \"RSME_48\", \"RSME_h96\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c1a2bcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_RUN_ID = \"9de69e1bb0844ca29f3267bca6f7674e\"\n",
    "BAYESIAN_LSTM_RUN_ID = \"2ccd3a12be4d4ec484be5af5fc8ab4e3\"\n",
    "PROPHET_RUN_ID = \"73f7dd056c9c4b38907b476f7bf47615\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8ca47f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3764089bb93416cb3026beee2955040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"load_forecasting_bayesian_lstm\")\n",
    "\n",
    "ranked_checkpoints = mlflow.search_logged_models(\n",
    "    filter_string=f\"source_run_id='{BAYESIAN_LSTM_RUN_ID}'\",\n",
    "    order_by=[{\"field_name\": \"metrics.val_nll\", \"ascending\": True}],\n",
    "    output_format=\"list\",\n",
    ")\n",
    "\n",
    "best_checkpoint = ranked_checkpoints[0]\n",
    "\n",
    "baysian_lstm = mlflow.pytorch.load_model(best_checkpoint.model_uri) # pyright: ignore\n",
    "\n",
    "run = mlflow.get_run(run_id=BAYESIAN_LSTM_RUN_ID)\n",
    "metrics = run.data.metrics\n",
    "\n",
    "rmse = run.data.metrics[\"test_rmse_unscaled\"]\n",
    "rmse_h1 = run.data.metrics[\"rmse_h1\"]\n",
    "rmse_h4 = run.data.metrics[\"rmse_h4\"]\n",
    "rmse_h12 = run.data.metrics[\"rmse_h12\"]\n",
    "rmse_h24 = run.data.metrics[\"rmse_h24\"]\n",
    "rmse_h48 = run.data.metrics[\"rmse_h48\"]\n",
    "rmse_h96 = run.data.metrics[\"rmse_h96\"]\n",
    "mae = run.data.metrics[\"test_mae_unscaled\"]\n",
    "\n",
    "perfomance_df.loc[len(perfomance_df)] = [\"bayesian_lstm\", rmse, mae, rmse_h1, rmse_h4, rmse_h12, rmse_h24, rmse_h48, rmse_h96]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2c77dff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e01da87e52514eed86d6ff545e9dfee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"load_forecasting_vanilla_lstm\")\n",
    "\n",
    "ranked_checkpoints = mlflow.search_logged_models(\n",
    "    filter_string=f\"source_run_id='{LSTM_RUN_ID}'\",\n",
    "    order_by=[{\"field_name\": \"metrics.val_mse\", \"ascending\": True}],\n",
    "    output_format=\"list\",\n",
    ")\n",
    "\n",
    "best_checkpoint = ranked_checkpoints[0]\n",
    "\n",
    "lstm = mlflow.pytorch.load_model(best_checkpoint.model_uri) # pyright: ignore\n",
    "\n",
    "run = mlflow.get_run(run_id=LSTM_RUN_ID)\n",
    "metrics = run.data.metrics\n",
    "\n",
    "rmse = run.data.metrics[\"test_rmse_unscaled\"]\n",
    "rmse_h1 = run.data.metrics[\"rmse_h1\"]\n",
    "rmse_h4 = run.data.metrics[\"rmse_h4\"]\n",
    "rmse_h12 = run.data.metrics[\"rmse_h12\"]\n",
    "rmse_h24 = run.data.metrics[\"rmse_h24\"]\n",
    "rmse_h48 = run.data.metrics[\"rmse_h48\"]\n",
    "rmse_h96 = run.data.metrics[\"rmse_h96\"]\n",
    "mae = run.data.metrics[\"test_mae_unscaled\"]\n",
    "\n",
    "perfomance_df.loc[len(perfomance_df)] = [\"lstm\", rmse, mae, rmse_h1, rmse_h4, rmse_h12, rmse_h24, rmse_h48, rmse_h96]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ea478936",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"load_forecasting_prophet\")\n",
    "\n",
    "ranked_checkpoints = mlflow.search_logged_models(\n",
    "    filter_string=f\"source_run_id='{PROPHET_RUN_ID}'\",\n",
    "    order_by=[{\"field_name\": \"metrics.val_mse\", \"ascending\": True}],\n",
    "    output_format=\"list\",\n",
    ")\n",
    "\n",
    "best_checkpoint = ranked_checkpoints[0]\n",
    "\n",
    "prophet_model = mlflow.prophet.load_model(best_checkpoint.model_uri) # pyright: ignore\n",
    "\n",
    "mlflow.get_run(run_id=PROPHET_RUN_ID)\n",
    "\n",
    "run = mlflow.get_run(run_id=PROPHET_RUN_ID)\n",
    "metrics = run.data.metrics\n",
    "\n",
    "rmse = run.data.metrics[\"rmse\"]\n",
    "rmse_h1 = run.data.metrics[\"rmse_h1\"]\n",
    "rmse_h4 = run.data.metrics[\"rmse_h4\"]\n",
    "rmse_h12 = run.data.metrics[\"rmse_h12\"]\n",
    "rmse_h24 = run.data.metrics[\"rmse_h24\"]\n",
    "rmse_h48 = run.data.metrics[\"rmse_h48\"]\n",
    "rmse_h96 = run.data.metrics[\"rmse_h96\"]\n",
    "mae = run.data.metrics[\"mae\"]\n",
    "\n",
    "perfomance_df.loc[len(perfomance_df)] = [\"prophet\", rmse, mae, rmse_h1, rmse_h4, rmse_h12, rmse_h24, rmse_h48, rmse_h96]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "29882f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RSME_Overall</th>\n",
       "      <th>MAE_Overall</th>\n",
       "      <th>RSME_h1</th>\n",
       "      <th>RSME_h4</th>\n",
       "      <th>RSME_h12</th>\n",
       "      <th>RSME_h24</th>\n",
       "      <th>RSME_48</th>\n",
       "      <th>RSME_h96</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bayesian_lstm</td>\n",
       "      <td>353.585541</td>\n",
       "      <td>250.205490</td>\n",
       "      <td>70.742035</td>\n",
       "      <td>151.687988</td>\n",
       "      <td>288.078064</td>\n",
       "      <td>363.448212</td>\n",
       "      <td>379.729950</td>\n",
       "      <td>378.285156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lstm</td>\n",
       "      <td>341.089600</td>\n",
       "      <td>218.389709</td>\n",
       "      <td>117.053764</td>\n",
       "      <td>175.866043</td>\n",
       "      <td>276.798492</td>\n",
       "      <td>325.508362</td>\n",
       "      <td>368.340179</td>\n",
       "      <td>377.863098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prophet</td>\n",
       "      <td>521.325481</td>\n",
       "      <td>418.771196</td>\n",
       "      <td>521.288097</td>\n",
       "      <td>521.292154</td>\n",
       "      <td>521.277565</td>\n",
       "      <td>521.352052</td>\n",
       "      <td>521.396901</td>\n",
       "      <td>521.368254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  RSME_Overall  MAE_Overall     RSME_h1     RSME_h4  \\\n",
       "0  bayesian_lstm    353.585541   250.205490   70.742035  151.687988   \n",
       "1           lstm    341.089600   218.389709  117.053764  175.866043   \n",
       "2        prophet    521.325481   418.771196  521.288097  521.292154   \n",
       "\n",
       "     RSME_h12    RSME_h24     RSME_48    RSME_h96  \n",
       "0  288.078064  363.448212  379.729950  378.285156  \n",
       "1  276.798492  325.508362  368.340179  377.863098  \n",
       "2  521.277565  521.352052  521.396901  521.368254  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perfomance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dbefc7",
   "metadata": {},
   "source": [
    "## Load the run error data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582c9ec9",
   "metadata": {},
   "source": [
    "## Comparisson Plots\n",
    "\n",
    "### RSME, MAE and Horizon-Error-Profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccd9706",
   "metadata": {},
   "source": [
    "## Sample predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9308b5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data Normal Weekday, Holiday, Weekend\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
